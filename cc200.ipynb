{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36907
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 424809,
     "status": "ok",
     "timestamp": 1544941260279,
     "user": {
      "displayName": "Xin Yang",
      "photoUrl": "",
      "userId": "18197329407244351054"
     },
     "user_tz": 360
    },
    "id": "ZR9yVSoXiBNO",
    "outputId": "8623e6f0-5f0e-49ca-f4be-877012af5e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nilearn in c:\\users\\alexr\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (1.2.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (4.9.3)\n",
      "Requirement already satisfied: nibabel>=3.2.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (1.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (23.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from nilearn) (1.11.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->nilearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Downloading data from https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required'))': /simple/nilearn/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required'))': /simple/nilearn/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required'))': /simple/nilearn/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required'))': /simple/nilearn/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required'))': /simple/nilearn/\n",
      "Error while fetching file Phenotypic_V1_0b_preprocessed1.csv; dataset fetching aborted."
     ]
    },
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Max retries exceeded with url: /fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:712\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_new_proxy_conn \u001b[38;5;129;01mand\u001b[39;00m http_tunnel_required:\n\u001b[1;32m--> 712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1012\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     conn\u001b[38;5;241m.\u001b[39mtls_in_tls_required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m conn\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:374\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Calls self._set_hostport(), so self.host is\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# self._tunnel_host below.\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel()\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# Mark this connection as not reusable\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:926\u001b[0m, in \u001b[0;36mHTTPConnection._tunnel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTunnel connection failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: Tunnel connection failed: 407 Proxy Authentication Required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    800\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    801\u001b[0m )\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Max retries exceeded with url: /fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_abide_pcp\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fetch the full data and update phenotypic data and cross_validation\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m abide \u001b[38;5;241m=\u001b[39m fetch_abide_pcp(derivatives \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrois_cc200\u001b[39m\u001b[38;5;124m'\u001b[39m], pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpac\u001b[39m\u001b[38;5;124m'\u001b[39m, quality_checked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m abide\u001b[38;5;241m.\u001b[39mphenotypic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDX_GROUP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nilearn\\datasets\\func.py:1162\u001b[0m, in \u001b[0;36mfetch_abide_pcp\u001b[1;34m(data_dir, n_subjects, pipeline, band_pass_filtering, global_signal_regression, derivatives, quality_checked, url, verbose, legacy_format, **kwargs)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;66;03m# Fetch the phenotypic file and load it\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhenotypic_V1_0b_preprocessed1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1162\u001b[0m path_csv \u001b[38;5;241m=\u001b[39m _fetch_files(\n\u001b[0;32m   1163\u001b[0m     data_dir, [(csv, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, {})], verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[0;32m   1164\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m# Note: the phenotypic file contains string that contains comma which mess\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m# up numpy array csv loading. This is why I do a pass to remove the last\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m# field. This can be\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m# done simply with pandas but we don't want such dependency ATM\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m# pheno = pandas.read_csv(path_csv).to_records()\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_csv) \u001b[38;5;28;01mas\u001b[39;00m pheno_f:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nilearn\\datasets\\utils.py:784\u001b[0m, in \u001b[0;36m_fetch_files\u001b[1;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m    783\u001b[0m         session\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mftp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, _NaiveFTPAdapter())\n\u001b[1;32m--> 784\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _fetch_files(\n\u001b[0;32m    785\u001b[0m             data_dir,\n\u001b[0;32m    786\u001b[0m             files,\n\u001b[0;32m    787\u001b[0m             resume\u001b[38;5;241m=\u001b[39mresume,\n\u001b[0;32m    788\u001b[0m             verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    789\u001b[0m             session\u001b[38;5;241m=\u001b[39msession,\n\u001b[0;32m    790\u001b[0m         )\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# There are two working directories here:\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# - data_dir is the destination directory of the dataset\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# - temp_dir is a temporary directory dedicated to this fetching call. All\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m#   files that must be downloaded will be in this directory. If a corrupted\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;66;03m#   file is found, or a file is missing, this working directory will be\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m#   deleted.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(files)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nilearn\\datasets\\utils.py:843\u001b[0m, in \u001b[0;36m_fetch_files\u001b[1;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[0;32m    840\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(temp_dir)\n\u001b[0;32m    841\u001b[0m md5sum \u001b[38;5;241m=\u001b[39m opts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd5sum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 843\u001b[0m dl_file \u001b[38;5;241m=\u001b[39m _fetch_file(\n\u001b[0;32m    844\u001b[0m     url,\n\u001b[0;32m    845\u001b[0m     temp_dir,\n\u001b[0;32m    846\u001b[0m     resume\u001b[38;5;241m=\u001b[39mresume,\n\u001b[0;32m    847\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    848\u001b[0m     md5sum\u001b[38;5;241m=\u001b[39mmd5sum,\n\u001b[0;32m    849\u001b[0m     username\u001b[38;5;241m=\u001b[39mopts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    850\u001b[0m     password\u001b[38;5;241m=\u001b[39mopts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    851\u001b[0m     session\u001b[38;5;241m=\u001b[39msession,\n\u001b[0;32m    852\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# XXX: here, move is supposed to be a dir, it can be a name\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     move \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(temp_dir, opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nilearn\\datasets\\utils.py:661\u001b[0m, in \u001b[0;36m_fetch_file\u001b[1;34m(url, data_dir, resume, overwrite, md5sum, username, password, verbose, session)\u001b[0m\n\u001b[0;32m    657\u001b[0m req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    658\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39murl, headers\u001b[38;5;241m=\u001b[39mheaders, auth\u001b[38;5;241m=\u001b[39mauth\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    660\u001b[0m prepped \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mprepare_request(req)\n\u001b[1;32m--> 661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    662\u001b[0m     prepped, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m_REQUESTS_TIMEOUT\n\u001b[0;32m    663\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m resp:\n\u001b[0;32m    664\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(temp_full_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:513\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _ProxyError):\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mProxyError\u001b[0m: HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Max retries exceeded with url: /fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 407 Proxy Authentication Required')))"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nilearn\n",
    "\n",
    "from nilearn.datasets import fetch_abide_pcp\n",
    "# Fetch the full data and update phenotypic data and cross_validation\n",
    "abide = fetch_abide_pcp(derivatives = ['rois_cc200'], pipeline = 'cpac', quality_checked = False)\n",
    "\n",
    "y = abide.phenotypic['DX_GROUP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtwZ7bHeiqdz"
   },
   "source": [
    "=====================================\n",
    "Logistic Regression:\n",
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBqIC2R-iJwi"
   },
   "outputs": [],
   "source": [
    "measure = 'correlation'\n",
    "C = [0.001, 0.01, 0.1]\n",
    "lr_params = {'C': C}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "y[y==2] = 0\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = measure)\n",
    "conn_matrices = conn_est.fit_transform(abide.rois_cc200)\n",
    "X = sym_matrix_to_vec(conn_matrices)\n",
    "\n",
    "gcv = GridSearchCV(lr, lr_params, n_jobs = -1, cv = skf, verbose = 1)\n",
    "gcv.fit(X, y)\n",
    "best_estimators = gcv.best_estimator_\n",
    "best_scores = gcv.best_score_\n",
    "\n",
    "\n",
    "print(\"best_estimators:\",best_estimators)\n",
    "print(\"best_scores:\",best_scores)\n",
    "\n",
    "'''\n",
    "best_estimators: [LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
    "          tol=0.0001, verbose=0, warm_start=False)]\n",
    "best_scores: [0.6908212560386473]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIGvgSl7j8Ra"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "#best parameter for each measure\n",
    "lr = LogisticRegression(C = 0.01)\n",
    "\n",
    "#recall == sensitivity\n",
    "recall = cross_val_score(lr, X, y, scoring = 'recall',cv = skf, verbose = 1)\n",
    "precision = cross_val_score(lr, X, y, scoring = 'precision',cv = skf, verbose = 1)\n",
    "    \n",
    "cross_recall = np.mean(recall)\n",
    "cross_precision = np.mean(precision)\n",
    "   \n",
    "print(\"cross_recall:\",cross_recall)\n",
    "print(\"cross_precision:\",cross_precision)  \n",
    "\n",
    "'''\n",
    "cross_recall: [0.6673267326732674]\n",
    "cross_precision: [0.6904341921519341]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gf1ZVIDwlZtY"
   },
   "source": [
    "==============================================\n",
    "Ridge\n",
    "=============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9i5_kVkk9Sg"
   },
   "outputs": [],
   "source": [
    "measure = 'correlation'\n",
    "alpha = [100,1000,10000]\n",
    "rc_params = {'alpha': alpha}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "rc = RidgeClassifier()\n",
    "\n",
    "y[y==2] = 0\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = measure)\n",
    "conn_matrices = conn_est.fit_transform(abide.rois_cc200)\n",
    "X = sym_matrix_to_vec(conn_matrices)\n",
    "\n",
    "gcv = GridSearchCV(rc, rc_params, n_jobs = -1, cv = skf, verbose = 1)\n",
    "gcv.fit(X, y)\n",
    "best_estimators = gcv.best_estimator_\n",
    "best_scores = gcv.best_score_\n",
    "\n",
    "\n",
    "print(\"best_estimators:\",best_estimators)\n",
    "print(\"best_scores:\",best_scores)\n",
    "\n",
    "'''\n",
    "best_estimators: [RidgeClassifier(alpha=1000, class_weight=None, copy_X=True,\n",
    "        fit_intercept=True, max_iter=None, normalize=False,\n",
    "        random_state=None, solver='auto', tol=0.001)]\n",
    "best_scores: [0.6927536231884058]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAHsjOgWltNv"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "#best parameter for each measure\n",
    "lr = RidgeClassifier(alpha=1000)\n",
    "\n",
    "#recall == sensitivity\n",
    "recall = cross_val_score(lr, X, y, scoring = 'recall',cv = skf, verbose = 1)\n",
    "precision = cross_val_score(lr, X, y, scoring = 'precision',cv = skf, verbose = 1)\n",
    "    \n",
    "cross_recall = np.mean(recall)\n",
    "cross_precision = np.mean(precision)\n",
    "  \n",
    "print(\"cross_recall:\",cross_recall)\n",
    "print(\"cross_precision:\",cross_precision)\n",
    "\n",
    "'''\n",
    "cross_recall: [0.6594059405940593]\n",
    "cross_precision: [0.6960889851629156]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oP7ltw_vm-4p"
   },
   "source": [
    "===========================================\n",
    "linearSVC l2\n",
    "==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 222407,
     "status": "ok",
     "timestamp": 1544942514267,
     "user": {
      "displayName": "Xin Yang",
      "photoUrl": "",
      "userId": "18197329407244351054"
     },
     "user_tz": 360
    },
    "id": "RVKX_C4klusD",
    "outputId": "fcdd9b35-59ec-4802-f6d7-a9445d5b5222"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimators: LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "best_scores: 0.6859903381642513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nbest_estimators: [LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)]\\nbest_scores: [0.6859903381642513]\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure = 'correlation'\n",
    "C = [0.0001, 0.001, 0.01]\n",
    "svc_params = {'C': C}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "svc_l2 = LinearSVC()\n",
    "\n",
    "y[y==2] = 0\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = measure)\n",
    "conn_matrices = conn_est.fit_transform(abide.rois_cc200)\n",
    "X = sym_matrix_to_vec(conn_matrices)\n",
    "\n",
    "gcv = GridSearchCV(svc_l2, svc_params, n_jobs = -1, cv = skf, verbose = 1)\n",
    "gcv.fit(X, y)\n",
    "best_estimators = gcv.best_estimator_\n",
    "best_scores = gcv.best_score_\n",
    "\n",
    "print(\"best_estimators:\",best_estimators)\n",
    "print(\"best_scores:\",best_scores)\n",
    "\n",
    "'''\n",
    "best_estimators: [LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)]\n",
    "best_scores: [0.6859903381642513]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 123135,
     "status": "ok",
     "timestamp": 1544944123389,
     "user": {
      "displayName": "Xin Yang",
      "photoUrl": "",
      "userId": "18197329407244351054"
     },
     "user_tz": 360
    },
    "id": "Q4Va8vDDnXN9",
    "outputId": "9c2403c0-211f-4b0c-ce3d-cb039ef9eeaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_recall: 0.6613861386138613\n",
      "cross_precision: 0.6856377307555428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncross_recall: [0.6613861386138613]\\ncross_precision: [0.6856377307555428]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "#best parameter for each measure\n",
    "lr = LinearSVC(C = 0.001)\n",
    "\n",
    "#recall == sensitivity\n",
    "recall = cross_val_score(lr, X, y, scoring = 'recall',cv = skf, verbose = 1)\n",
    "precision = cross_val_score(lr, X, y, scoring = 'precision',cv = skf, verbose = 1)\n",
    "    \n",
    "cross_recall = np.mean(recall)\n",
    "cross_precision = np.mean(precision)\n",
    "\n",
    "print(\"cross_recall:\",cross_recall)\n",
    "print(\"cross_precision:\",cross_precision)\n",
    "\n",
    "'''\n",
    "cross_recall: [0.6613861386138613]\n",
    "cross_precision: [0.6856377307555428]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aexi90Nfvv2L"
   },
   "source": [
    "=====================================\n",
    "svm rbf\n",
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479390,
     "status": "ok",
     "timestamp": 1544944621479,
     "user": {
      "displayName": "Xin Yang",
      "photoUrl": "",
      "userId": "18197329407244351054"
     },
     "user_tz": 360
    },
    "id": "Ys9V6fYVogfA",
    "outputId": "876d799e-82c0-4477-a51c-c4f8f8af3a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimators: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best_scores: 0.6811594202898551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nbest_estimators: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)\\nbest_scores: 0.6811594202898551\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure = 'correlation'\n",
    "C = [1,10,100]\n",
    "svc_params = {'C': C}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "svc_rbf = SVC(gamma='auto')\n",
    "\n",
    "y[y==2] = 0\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "\n",
    "conn_est = ConnectivityMeasure(kind = measure)\n",
    "conn_matrices = conn_est.fit_transform(abide.rois_cc200)\n",
    "X = sym_matrix_to_vec(conn_matrices)\n",
    "\n",
    "gcv = GridSearchCV(svc_rbf, svc_params, n_jobs = -1, cv = skf, verbose = 1)\n",
    "gcv.fit(X, y)\n",
    "best_estimators = gcv.best_estimator_\n",
    "best_scores = gcv.best_score_\n",
    "\n",
    "print(\"best_estimators:\",best_estimators)\n",
    "print(\"best_scores:\",best_scores)\n",
    "\n",
    "'''\n",
    "best_estimators: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "best_scores: 0.6811594202898551\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 282991,
     "status": "ok",
     "timestamp": 1544944919135,
     "user": {
      "displayName": "Xin Yang",
      "photoUrl": "",
      "userId": "18197329407244351054"
     },
     "user_tz": 360
    },
    "id": "qcc_x-CQwM07",
    "outputId": "8895b4e6-19fb-4a7a-af0e-c8636c7bb585"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_recall: 0.6257425742574256\n",
      "cross_precision: 0.693116442730704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncross_recall: [0.6613861386138613]\\ncross_precision: [0.6856377307555428]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "#best parameter for each measure\n",
    "lr = SVC(gamma='auto',C=10)\n",
    "\n",
    "#recall == sensitivity\n",
    "recall = cross_val_score(lr, X, y, scoring = 'recall',cv = skf, verbose = 1)\n",
    "precision = cross_val_score(lr, X, y, scoring = 'precision',cv = skf, verbose = 1)\n",
    "    \n",
    "cross_recall = np.mean(recall)\n",
    "cross_precision = np.mean(precision)\n",
    "\n",
    "print(\"cross_recall:\",cross_recall)\n",
    "print(\"cross_precision:\",cross_precision)\n",
    "\n",
    "'''\n",
    "cross_recall: 0.6257425742574256\n",
    "cross_precision: 0.693116442730704\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0vNlLJb6Wx5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cc200.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
